[{"url": "http://www.improvedoutcomes.com/docs/WebSiteDocs/Clustering/K-Means_Clustering_Overview.htm", "passage_text": "Advantages to Using this Technique. With a large number of variables, K-Means may be computationally faster than hierarchical clustering (if K is small). K-Means may produce tighter clusters than hierarchical clustering, especially if the clusters are globular. The version of the K-Means algorithm used in GeneLinker differs from the conventional K-Means algorithm in that GeneLinker does not compute the centroid of the clusters to measure the distance from a data point to a cluster."}, {"url": "http://playwidtech.blogspot.com/2013/02/k-means-clustering-advantages-and.html", "passage_text": "K-Means Advantages : 1) If variables are huge, then K-Means most of the times computationally faster than hierarchical clustering, if we keep k smalls. 2) K-Means produce tighter clusters than hierarchical clustering, especially if the clusters are globular. K-Means Disadvantages : 1) Difficult to predict K-Value. 2) With global cluster, it didn't work well."}, {"url": "http://www.sciencedirect.com/science/article/pii/S1875389212006220", "passage_text": "The improved K-Means algorithm effectively solved two disadvantages of the traditional algorithm, the first one is greater dependence to choice the initial focal point, and another one is easy to be trapped in local minimum [1] and [2] . "}, {"url": "https://en.wikipedia.org/wiki/K-means_clustering", "passage_text": "In cluster analysis, the k-means algorithm can be used to partition the input data set into k partitions (clusters). However, the pure k-means algorithm is not very flexible, and as such is of limited use (except for when vector quantization as above is actually the desired use case!). It was asserted in that the relaxed solution of k-means clustering, specified by the cluster indicators, is given by the PCA (principal component analysis) principal components, and the PCA subspace spanned by the principal directions is identical to the cluster centroid subspace."}, {"url": "https://en.wikipedia.org/wiki/K-means_clustering", "passage_text": "k-means clustering is a method of vector quantization, originally from signal processing, that is popular for cluster analysis in data mining. k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. It was asserted in that the relaxed solution of k-means clustering, specified by the cluster indicators, is given by the PCA (principal component analysis) principal components, and the PCA subspace spanned by the principal directions is identical to the cluster centroid subspace."}, {"url": "http://databases.about.com/od/datamining/a/kmeans.htm", "passage_text": "k-means clustering is a data mining/machine learning algorithm used to cluster observations into groups of related observations without any prior knowledge of those relationships. The k-means algorithm is one of the simplest clustering techniques and it is commonly used in medical imaging, biometrics and related fields. 1 The algorithm arbitrarily selects k points as the initial cluster centers (\u201cmeans\u201d). 2  Each point in the dataset is assigned to the closed cluster, based upon the Euclidean distance between each point and each cluster center. 3  Each cluster center is recomputed as the average of the points in that cluster."}, {"url": "http://www.improvedoutcomes.com/docs/WebSiteDocs/Clustering/K-Means_Clustering_Overview.htm", "passage_text": "The K-Means Algorithm Process. The dataset is partitioned into K clusters and the data points are randomly assigned to the clusters resulting in clusters that have roughly the same number of data points. For each data point: Calculate the distance from the data point to each cluster. The version of the K-Means algorithm used in GeneLinker differs from the conventional K-Means algorithm in that GeneLinker does not compute the centroid of the clusters to measure the distance from a data point to a cluster."}, {"url": "http://www.bindichen.co.uk/post/AI/fuzzy-c-means.html", "passage_text": "Advantages: 1  Gives best result for overlapped data set and comparatively better than k-means algorithm. 2  Unlike k-means where data point must exclusively belong to one cluster center here data point is assigned membership to each cluster center as a result of which data point may belong to more than one cluster center. "}, {"url": "http://ijcem.org/papers42011/42011_26.pdf", "passage_text": "1. Introduction 1.1 K-means algorithm: K-means clustering is a method of cluster analysis which aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean. It is one of the simplest unsupervised learning algorithms that solve the well known clustering problem. The k-means algorithm is an evolutionary algorithm that gains its name from its method of operation. The algorithm clusters observations into k groups, where k is provided as an input parameter. It then assigns each observation to clusters based upon the observation\u2019s proximity to the mean of the cluster"}, {"url": "http://www.improvedoutcomes.com/docs/WebSiteDocs/Clustering/K-Means_Clustering_Overview.htm", "passage_text": "K-Means Clustering in GeneLinker. The version of the K-Means algorithm used in GeneLinker differs from the conventional K-Means algorithm in that GeneLinker does not compute the centroid of the clusters to measure the distance from a data point to a cluster. Instead, the algorithm uses a specified linkage distance metric"}]