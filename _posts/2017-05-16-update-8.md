---
layout: post
title: Multi-passage Model Update
comments: true
---

### [](#header-3)Completed BiDAF
(Maybe talk about how it was more complex than the diagram implied)


### [](#header-3)Introduced Multiple Passages
We figured with time running short, it was time to start to encorporate multiple passages into the model. In our eyes, there were two main ways of doing this, first, feed all the passages into the model and have some sort of attention mechanism find the relevant passages. The second option would be to calculate a probability of how relevant the passage was, then feed each passage through the model, take the probability distribution of the start and end index over the words, multiple the probabilities by the probability that the passage is relevant, and finally taking an argmax to find the answer.

For this first attempt at the multi-passage model, we decided to go with the first option with advice from Maarten. But instead of having a set of learned attention waits, we took the cosine similarities of the tf-idf vectors mentioned last week, and performed a softmax over them to get probability distribution of which passages are relevant. From there, we apply these weights to the output vectors from the 'Context Embed Layer' viewed below.

![BiDAF Diagram]({{ site.baseurl }}/img/post-8/BiDAF.jpg)<br/>

Since this was our first attempt, we stuck with just concatenating the inputs together to make one long string. In future attempts, it may be beneficial to have the LSTM in the 'Context Embed Layer' read only single passages at a time, so it does not need to learn to embed context from multiple different passages at once.

Running the model for 50 epochs, with an embedding and hidden size of 50, and a learning rate of 0.01, we got the following results:

| Metric  | BiDAF-Multi |
| ------- | ------------------ |
| Bleu-1  | 0.101 |
| Bleu-2  | 0.081 |
| Bleu-3  | 0.070 |
| Bleu-4  | 0.062 |
| Rouge-L | 0.291 |

### [](#header-3)How to Improve
(Talk with Minjoon, Argmax, Sort passages before concatenation)


### [](#header-3)Error Analysis


### [](#header-3)Demo Work