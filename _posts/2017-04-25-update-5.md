---
layout: post
title: Multiple Baseline Models' Performance and Error Analysis
comments: true
---

### [](#header-3)Baseline Model (Old)

For our baseline model, we started with a very basic design. The model has two bi-directional dynamic GRU RNN's. The first RNN takes a matrix of the word embeddings of the question, and the second RNN takes the word embeddings of the context. The output of each RNN is the concatenation of the backward and forward outputs of that RNN. The output of the question RNN is a matrix representing a vector for each word in the question. The question representation we later consider is an average of the different word vectors outputed from the question RNN. The question representation and the output of the context RNN are concatenated and inserted in a third bi-directional dynamic GRU RNN. Then, we have a dense output layer that takes the output of the third RNN. From the output layer we get the logits for the starting and ending indices of the answer, from which we take the arg max. All three RNN's have a dropout as a regularization technique to reduce overfitting during training.

![Overview of the model from Tensorboard]({{ site.baseurl }}/img/post-5/baseline_graph_1.JPG)
![The expansion of the question encoding block]({{ site.baseurl }}/img/post-5/baseline_graph_2.JPG)
![The expansion of the context encoding block]({{ site.baseurl }}/img/post-5/baseline_graph_3.JPG)
![The expansion of the post process block]({{ site.baseurl }}/img/post-5/baseline_graph_4.JPG)

[baseline_model.py](https://github.com/tgilbrough/MrKnowItAll/blob/master/baseline_model.py)

### [](#header-3)Baseline Attention Model (New)

The attention model is very similar to the old baseline model. The only difference is in defining the question representation that we use in the third RNN. Before, we used to average the difference word vectors we're getting from the question RNN, we do a weighted average with trained weights.

![Overview of the model from Tensorboard]({{ site.baseurl }}/img/post-5/attention_graph_1.JPG)
![The expansion of the encoding block]({{ site.baseurl }}/img/post-5/attention_graph_2.JPG)
![The expansion of the attention block]({{ site.baseurl }}/img/post-5/attention_graph_3.JPG)
![The expansion of the post process block]({{ site.baseurl }}/img/post-5/attention_graph_4.JPG)

[attention_model.py](https://github.com/tgilbrough/MrKnowItAll/blob/master/attention_model.py)

### [](#header-3)Initial Hyperparameter Tuning

These baseline models have multiple hyperparameters to tune, all of which can be controlled through the command line interface. So far, our list includes:

- **Keep Probability** - Used to configure all dropout layers within the model
- **Embeddings Size** Attention - Can be 50, 100, 200, or 300. Chooses which pretrained embeddings to load
- **Learning Rate** - Used as the hyperparameter within the model optimizer
- **Hidden Size** - Dimensions of hidden layers within RNN cells for encoding and decoding data
- **Epochs** - Number of passes over the training data
- **Batch Size** - Number of training samples to feed into the system at once, greatly effects runtime on GPU

In addition to these hyperparameters, the command line interface can also configure which model to use as well as which question type. With all this, we decided to run a couple of experiments in order to get a rough idea of what makes good default values for these values. We captured the results in Tensorboard, which are displayed below. As a note, the overall loss is the sum of the loss for the starting and ending index losses. Those indivudal losses are measuring exact matches of those indices.

For these experiments, we trained and tested on the location question type, for 50 epochs, with an embedding size of 50. We varied the batch size based on the model, since using too large of a batch size casued OOM (Out of Memory) errors. Therefore we will analyze the effect of different keep probabilities, learning rates, and hidden sizes.


![Baseline Keep Prob]({{ site.baseurl }}/img/post-5/baseline_keepprob.png)
![Attention Keep Prob]({{ site.baseurl }}/img/post-5/attention_keepprob.png)

![Baseline Learning Rate]({{ site.baseurl }}/img/post-5/baseline_learningrate.png)
![Attention Learning Rate]({{ site.baseurl }}/img/post-5/attention_learningrate.png)

![Baseline Hidden Size]({{ site.baseurl }}/img/post-5/baseline_hiddensize.png)
![Attention Hidden Size]({{ site.baseurl }}/img/post-5/attention_hiddensize.png)


### [](#header-3)Performance of Attention vs. Non-Attention Model

### Error Analysis
