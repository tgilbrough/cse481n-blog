---
layout: post
title: Advanced Model Update #1
comments: true
hidden: true
---

### [](#header-3)What We Are Trying
For our first advanced model, we decided to attempt to implement the model presented in Salesforce Research's paper, Dynamic Coattention Networks. The paper was very well written, with clear explanations, and was state-of-the-art on the SQuAD dataset was the paper came out. At this stage of the project, we are still trying to perfect the models ability to find an answer within the selected passage it is fed. 

As presented in the paper, there are two major components to this model:

- **Coattention Encoder** - An attention mechanism that accounts for the important words in the passage in light of the question, and the important words in the question in light of the passage. Inutiatively, this is like reading the question first and then searching the passage for the answer by looking for words that seem particularly relevant. 
- **Dynamic Decoder** - This is an iterative approach to decode an answer. The start and end index are in conversation with each other as they converge to a solution the model thinks is best. Within each iteration, the paper makes use of an LSTM, as well as a "highway maxout network" for each the start and end index.
 
### [](#header-3)What is Going Wrong

### [](#header-3)Results So Far

### [](#header-3)Next Steps
